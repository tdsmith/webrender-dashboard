---
output:
  html_document:
    self_contained: false
    df_print: "kable"
    toc: true
    toc_float: true
params:
  dbname: "webrender_nvidia.sqlite3"
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width=10, fig.height=4, message=FALSE, warning=FALSE)

library(RSQLite)
library(dplyr)
library(ggplot2)
library(readr)
library(tidyr)

ensure = function(df, ...) {
  if(nrow(df) == 0) return(df)
  cols = list(...)
  for(col in cols) {
    if(!(col %in% colnames(df))) {
      df = data.frame(df)
      df[, col] = NA
    }
  }
  df
}

min_build_id = c(
  nvidia="20180924100354",
  amd="20190130000000",
  intel="20190201000000"
)

mfr = sub(".*webrender_([^.]+).sqlite3", "\\1", params$dbname)

burndown = read_csv("bugzilla.csv")

cache = DBI::dbConnect(SQLite(), dbname=params$dbname)
users_by_build = tbl(cache, "users_by_build") %>% collect  %>% intake_filter

allowed_builds = bind_rows(
    users_by_build %>% group_by(normalized_channel, app_build_id) %>% summarize(n=sum(n)) %>% filter(n > 250, normalized_channel == "nightly"),
    users_by_build %>% group_by(normalized_channel, app_build_id) %>% summarize(n=sum(n)) %>% filter(n > 2500, normalized_channel == "beta")
  ) %>%
  select(normalized_channel, app_build_id)

intake_filter = function(df) {
  filter(
    df,
    !(app_build_id %in% c(
      "20181025143507", # beta; may not have escaped mozilla?
      "20180926142037" # crashy nightly; got respun
      )),
    # FIXME when 65 goes to beta
    (normalized_channel != "beta") | (app_build_id <= "20181128185223") | (app_build_id >= "20181210000000"),
    app_build_id >= min_build_id[mfr]
  ) %>%
  inner_join(allowed_builds)
}

crashes_per_build = tbl(cache, "crashes_per_build") %>% collect %>% intake_filter
crashes_per_build_per_process = tbl(cache, "crashes_per_build_per_process") %>% collect %>% intake_filter
perf_medians = tbl(cache, "perf_medians") %>% collect %>% intake_filter
paint_time_quantiles = tbl(cache, "paint_time_quantiles") %>% collect %>% intake_filter

slow_content_frame_time_summary = tbl(cache, "slow_content_frame_time_summary") %>% collect %>% intake_filter
slow_content_frame_time_vsync_summary = tbl(cache, "slow_content_frame_time_vsync_summary") %>% collect %>% intake_filter
slow_content_paint_time_summary = tbl(cache, "slow_content_paint_time_summary") %>% collect %>% intake_filter
slow_content_full_paint_time_summary = tbl(cache, "slow_content_full_paint_time_summary") %>% collect %>% intake_filter
slow_composite_time_summary = tbl(cache, "slow_composite_time_summary") %>% collect %>% intake_filter

intensity_summary = tbl(cache, "intensity_summary") %>% collect
uri_summary = tbl(cache, "uri_summary") %>% collect

enrollment_summary = tbl(cache, "enrollment_summary") %>% collect
unenrollment_summary = tbl(cache, "unenrollment_summary") %>% collect

nightly_perf_summary = tbl(cache, "nightly_perf_summary") %>% collect
beta_perf_summary = tbl(cache, "beta_perf_summary") %>% collect

metadata = tbl(cache, "metadata") %>% collect
last_update = metadata$last_update

# --

all_build_df = perf_medians %>% distinct(normalized_channel, app_build_id) %>% ungroup
recent_builds = bind_rows(
  all_build_df %>% filter(normalized_channel == "nightly") %>% top_n(14, app_build_id),
  all_build_df %>% filter(normalized_channel == "beta") %>% top_n(5, app_build_id)
)

all_builds = all_build_df %>% arrange(normalized_channel, app_build_id) %>% pull(app_build_id)

skip_n = function(n) {
  function(x) {
    sparse = setNames(rep("", length(x)), x)
    label_idx = rep_len(c(TRUE, rep(FALSE, n)), length(x))
    sparse[label_idx] = x[label_idx]
    sparse
  }
}
```

# WebRender Status (`r mfr`)

Last updated: `r last_update` UTC

# Executive summary

```{r burndown_combined}
burndown %>%
  mutate(Priority=factor(Priority, c("P3", "P2", "P1"))) %>%
  ggplot(aes(Day, Count, fill=Priority)) +
    geom_area(alpha=0.8) +
    geom_line(color="white", position="stack", size=1) +
    labs(x="Date", title="Bug burndown") +
    scale_x_date(date_breaks="1 month") +
    scale_fill_manual(values=c(P1="#fc8d62", P2="#8da0cb", P3="#66c2a5")) +
    theme(legend.position="bottom")
```

**[P1][p1]**: Blocking beta; **[P2][p2]**: Blocking release (being worked on or looking for owners); **[P3][p3]**: Wanted for release, but not blocking

## Nightly performance

```{r last_build}
last_build_id = crashes_per_build %>%
  filter(normalized_channel == "nightly") %>%
  select(app_build_id, branch, usage_hours) %>%
  spread(branch, usage_hours) %>%
  ensure("enabled", "disabled") %>%
  filter(enabled >= 1000, disabled >= 1000) %>%
  arrange(desc(app_build_id)) %>%
  head(1) %>%
  pull(app_build_id)

most_recent_beta_builds = crashes_per_build %>%
  filter(normalized_channel == "beta") %>%
  select(normalized_channel, app_build_id, branch, usage_hours) %>%
  spread(branch, usage_hours) %>%
  ensure("enabled", "disabled") %>%
  filter(enabled >= 10000, disabled >= 10000) %>%
  arrange(desc(app_build_id)) %>%
  select(normalized_channel, app_build_id) %>%
  top_n(1, app_build_id)

last_beta_build = most_recent_beta_builds %>% pull(app_build_id)
```

Performance of the last build with at least 1,000 accumulated usage hours/branch (` `r last_build_id` `):

```{r nightly_performance}
if(length(last_build_id) == 0) {
  cat("No build met the usage criterion.")
} else {
  nightly_perf_summary %>%
    filter(metric != "content_frame_time_vsync", metric != "slow_content_frame_time") %>%
    arrange(desc(y)) %>%
    mutate(`95% CI`=sprintf("(%.1f, %.1f)", ymin, ymax)) %>%
    mutate(y=sprintf("%.1f%%", y)) %>%
    select(Metric=metric, Median=y, `95% CI`)
}
```

WebRender performance expressed as percent of Gecko. Lower is better. Confidence intervals are bootstrapped.

## Beta performance

Performance of the last build with at least 10,000 accumulated usage hours/branch (` `r last_beta_build` `):

```{r recent_beta_performance}
if(length(last_beta_build) == 0) {
  cat("No build met the usage criterion.")
} else {
beta_perf_summary %>%
  filter(metric != "content_frame_time_vsync", metric != "slow_content_frame_time") %>%
  arrange(desc(y)) %>%
  mutate(`95% CI`=sprintf("(%.1f%%, %.1f%%)", ymin, ymax)) %>%
  mutate(y=sprintf("%.1f%%", y)) %>%
  select(Metric=metric, Median=y, `95% CI`)
}
```

WebRender performance expressed as percent of Gecko. Lower is better. Confidence intervals are bootstrapped.

<hr style="border: solid black 1px;">

# Performance

## CONTENT_FRAME_TIME_VSYNC

#### Recent builds

```{r content_frame_time_vsync_threshold}
slow_content_frame_time_vsync_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FRAME_TIME_VSYNC: per-user percent of frames exceeding 200% vsync", x="Build ID", y="Median percentage")
```

#### All builds

```{r content_frame_time_vsync_longitudinal}
slow_content_frame_time_vsync_summary %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.4) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FRAME_TIME_VSYNC: per-user percent of frames exceeding 200% vsync", x="Build ID", y="Median percentage") +
    coord_cartesian(ylim=c(0, 12))
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

CONTENT_FRAME_TIME_VSYNC is expressed in percent of a vsync.
Since display updates only occur at vsync intervals,
all updates that take between 100% and 200% of a vsync
appear identical to the user.
200% is therefore a critical threshold, so it's important to know how often frames are slower than 200%.

## Tab switch

#### Recent builds

```{r tab_switch_composite_mean}
perf_medians %>%
  inner_join(recent_builds) %>%
  filter(metric=="tab_switch_composite") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="FX_TAB_SWITCH_COMPOSITE_E10S_MS [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

#### All builds

```{r tab_switch_composite_mean_longitudinal}
perf_medians %>%
  filter(metric=="tab_switch_composite") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    scale_x_discrete(labels=skip_n(10)) +
    labs(title="FX_TAB_SWITCH_COMPOSITE_E10S_MS [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

## Page load

#### Recent builds

```{r page_load_mean}
perf_medians %>%
  inner_join(recent_builds) %>%
  filter(metric=="page_load_ms") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="FX_PAGE_LOAD_MS_2 [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

#### All builds

```{r page_load_mean_longitudinal}
perf_medians %>%
  filter(metric=="page_load_ms", !is.na(user_median)) %>%
  filter(app_build_id > "20181122") %>%  # initial implementation was wrong
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x", drop=TRUE) +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    scale_x_discrete(labels=skip_n(10)) +
    labs(title="FX_PAGE_LOAD_MS_2 [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

## CONTENT_FULL_PAINT_TIME

#### Recent builds

```{r content_full_paint_time_mean}
perf_medians %>%
  inner_join(recent_builds) %>%
  filter(metric=="content_full_paint_time") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    coord_cartesian(ylim=c(0, 5)) +
    labs(title="CONTENT_FULL_PAINT_TIME [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

```{r slow_content_full_paint_time}
slow_content_full_paint_time_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FULL_PAINT_TIME: per-user percent of frames exceeding 16ms", x="Build ID", y="Median percentage")
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

#### All builds

```{r content_full_paint_mean_longitudinal}
perf_medians %>%
  filter(metric=="content_full_paint_time", !is.na(user_median)) %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    scale_x_discrete(labels=skip_n(10)) +
    labs(title="CONTENT_FULL_PAINT_TIME [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```


```{r slow_content_full_paint_time_longitudinal}
slow_content_full_paint_time_summary %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FULL_PAINT_TIME: per-user percent of frames exceeding 16ms", x="Build ID", y="Median percentage")
```


## CONTENT_PAINT_TIME

#### Recent builds

```{r content_paint_time_mean}
perf_medians %>%
  inner_join(recent_builds) %>%
  filter(metric=="content_paint_time") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

```{r content_paint_time_p99}
paint_time_quantiles %>%
  inner_join(recent_builds) %>%
  filter(quantile == 0.99) %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME [ms]: per-user 99th %ile", x="Build ID", y="Median of per-user p99")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user p99s, treating the per-user p99s
as log-normally distributed.

```{r slow_content_paint_time}
slow_content_paint_time_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME: per-user percent of frames exceeding 16ms", x="Build ID", y="Median percentage")
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

#### All builds

```{r content_paint_time_mean_longitudinal}
perf_medians %>%
  filter(metric=="content_paint_time") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```


```{r content_paint_time_p99_longitudinal}
paint_time_quantiles %>%
  filter(quantile == 0.99) %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME [ms]: per-user 99th %ile", x="Build ID", y="Median of per-user p99")
```


```{r slow_content_paint_time_longitudinal}
slow_content_paint_time_summary %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.3) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_PAINT_TIME: per-user percent of frames exceeding 16ms", x="Build ID", y="Median percentage")
```

## COMPOSITE_TIME

```{r composite_time_mean}
perf_medians %>%
  inner_join(recent_builds) %>%
  filter(metric=="composite_time") %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    coord_cartesian(ylim=c(0, 5)) +
    labs(title="COMPOSITE_TIME [ms]: per-user mean", x="Build ID", y="Median of per-user means")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

```{r slow_composite_time}
slow_composite_time_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="COMPOSITE_TIME: per-user percent of frames exceeding 16ms", x="Build ID", y="Median percentage")
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

## CONTENT_FRAME_TIME

#### Recent builds

```{r content_frame_time_threshold}
slow_content_frame_time_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FRAME_TIME: per-user percent of frames exceeding 192% vsync", x="Build ID", y="Median percentage")
```

#### All builds

```{r content_frame_time_longitudinal}
slow_content_frame_time_summary %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_ribbon(alpha=0.4) +
    geom_line(aes(color=branch)) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(title="CONTENT_FRAME_TIME: per-user percent of frames exceeding 192% vsync", x="Build ID", y="Median percentage") +
    coord_cartesian(ylim=c(0, 6))
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

CONTENT_FRAME_TIME is expressed in percent of a vsync.
Since display updates only occur at vsync intervals,
all updates that take between 100% and 200% of a vsync
appear identical to the user.
200% is therefore a critical threshold, so it's important to know how often frames are slower than 200%.
We actually measure the fraction of events slower than 192% of a vsync
because, the way the histogram is defined, that's the closest bucket edge to 200%.

## Checkerboarding events

```{r total_checkerboard_rate_longitudinal}
crashes_per_build %>%
  mutate(
    cbmin=qchisq(0.025, 2*severe_checkerboard_events)/2,
    cbmax=qchisq(0.975, 2*(severe_checkerboard_events+1))/2
  ) %>%
  ggplot(aes(app_build_id, severe_checkerboard_events/usage_hours*1000, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_ribbon(aes(ymin=cbmin/usage_hours*1000, ymax=cbmax/usage_hours*1000), alpha=0.4) +
    geom_line(aes(color=branch)) +
    # coord_cartesian(ylim=c(0, 0.1)*1000) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Checkerboard rate", title="Checkerboard rate trend: severe checkerboarding events per 1000 usage hours")
```


# Crash summary

Be cautious when interpreting crash rates from recent builds.
We receive pings that tell us about crashes before we receive pings that tell us about usage,
so estimates of crash rates are much higher than the true rate for the first few days builds are in the field.

### Nightly

Stability of the last 14 builds with at least 1,000 usage-hours/branch, combined:

```{r recent_nightly_crash_summary}
most_recent_builds = crashes_per_build %>%
  filter(normalized_channel == "nightly") %>%
  select(normalized_channel, app_build_id, branch, usage_hours) %>%
  spread(branch, usage_hours) %>%
  filter(enabled >= 1000, disabled >= 1000) %>%
  select(normalized_channel, app_build_id) %>%
  top_n(14, app_build_id)

my_test = function(x) {
  disabled = filter(x, branch == "disabled")
  enabled = filter(x, branch == "enabled")
  if(nrow(enabled)*nrow(disabled) == 0) {
    return(data.frame(vs_gecko=NA, ci_low=NA, ci_high=NA, p_value=NA))
  }
  result = poisson.test(c(enabled$crashes, disabled$crashes), c(enabled$hours, disabled$hours), r=1)
  data.frame(
    vs_gecko=result$estimate,
    ci_low=result$conf.int[1],
    ci_high=result$conf.int[2],
    p_value=result$p.value
  )
}

nightly_stability = crashes_per_build %>%
  inner_join(most_recent_builds) %>%
  gather(metric, value, ends_with("crashes"), device_reset_reason_total) %>%
  group_by(metric, branch) %>%
  summarize(crashes=sum(value), hours=sum(usage_hours)) %>%
  group_by(metric) %>%
  do(my_test(.)) %>%
  mutate(regression=(vs_gecko > 1) & (p_value < .05))

ggplot(nightly_stability, aes(metric, vs_gecko, ymin=ci_low, ymax=ci_high, color=regression)) +
  geom_pointrange() +
  geom_hline(yintercept=1) +
  scale_color_manual(values=c("TRUE"="red", "FALSE"="black"), drop=FALSE) +
  scale_y_continuous(labels=scales::percent) +
  expand_limits(color=TRUE, y=0) +
  labs(x="Crash type", y="WebRender rate (% of Gecko)", title="Nightly WebRender crash rate summary (vs Gecko)")
```

Error bars reflect a 95% confidence interval for the ratio of Poisson rates adjusted for total usage hours.

### Beta

Stability of the last build with at least 10,000 usage-hours/branch:

```{r recent_beta_crash_summary}
beta_stability = crashes_per_build %>%
  inner_join(most_recent_beta_builds) %>%
  gather(metric, value, ends_with("crashes"), device_reset_reason_total) %>%
  group_by(metric, branch) %>%
  summarize(crashes=sum(value), hours=sum(usage_hours)) %>%
  group_by(metric) %>%
  do(my_test(.)) %>%
  mutate(regression=(vs_gecko > 1) & (p_value < .05))

ggplot(beta_stability, aes(metric, vs_gecko, ymin=ci_low, ymax=ci_high, color=regression)) +
  geom_pointrange() +
  geom_hline(yintercept=1) +
  scale_color_manual(values=c("TRUE"="red", "FALSE"="black"), drop=FALSE) +
  scale_y_continuous(labels=scales::percent) +
  expand_limits(color=TRUE, y=0) +
  labs(x="Crash type", y="WebRender rate (% of Gecko)", title="Beta WebRender crash rate summary (vs Gecko)")
```

### Recent builds

```{r total_crash_rate}
crashes_per_build %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, total_crashes/usage_hours*1000, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    geom_errorbar(position=position_dodge(w=1), width=0.2, mapping=aes(ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1.0)) +
    coord_cartesian(ylim=c(0, 0.1)*1000) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash rate", title="Crash rate: all crashes (main+content+gpu) per 1000 usage hours")
```

### All builds

```{r total_crash_rate_longitudinal}
crashes_per_build %>%
  ggplot(aes(app_build_id, total_crashes/usage_hours*1000, fill=branch, group=branch)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_ribbon(aes(ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000), alpha=0.4) +
    geom_line(aes(color=branch)) +
    coord_cartesian(ylim=c(0, 0.1)*1000) +
    scale_x_discrete(labels=skip_n(10)) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash rate", title="Crash rate trend: all crashes (main+content+gpu) per 1000 usage hours")
```

Crash rate error bars reflect 95% confidence intervals for rates,
assuming that crashes are Poisson-distributed,
and based on received usage.
Error bars do _not_ account for the reporting delay between crashes and non-crash usage.

# Crash detail

```{r total_crash_count}
crashes_per_build %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, total_crashes, fill=branch)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Count of all crashes", title="All crashes (main+content+gpu)")
```


```{r device_reset_rate}
crashes_per_build %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, device_reset_reason_total/usage_hours*1000, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    geom_errorbar(
      mapping=aes(
        ymin=qchisq(0.025, 2*device_reset_reason_total)/2/usage_hours*1000,
        ymax=qchisq(0.975, 2*(device_reset_reason_total+1))/2/usage_hours*1000
      ),
      width=0.2,
      position=position_dodge(width=1)
    ) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    coord_cartesian(ylim=c(0, 0.05)*1000) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(title="Device resets per 1000 usage hours", x="Build ID", y="Reset rate")
```

```{r crash_process_main}
crashes_per_build_per_process %>%
  filter(process == "main") %>%
  full_join(crashes_per_build %>% distinct(normalized_channel, app_build_id, branch)) %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, total_crashes/usage_hours*1000, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    geom_errorbar(position=position_dodge(w=1), width=0.2, mapping=aes(ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    coord_cartesian(ylim=c(0, 0.02)*1000) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash rate", title="Crashes per 1000 usage-hours: main process")
```

```{r crash_process_content}
crashes_per_build_per_process %>%
  inner_join(recent_builds) %>%
  filter(process == "content") %>%
  ggplot(aes(app_build_id, total_crashes/usage_hours*1000, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    geom_errorbar(position=position_dodge(w=1), width=0.2, mapping=aes(ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    coord_cartesian(ylim=c(0, 0.03)*1000) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash rate", title="Crashes per 1000 usage-hours: content process")
```

```{r crash_process_gpu}
crashes_per_build_per_process %>%
  filter(process == "gpu") %>%
  full_join(crashes_per_build %>% distinct(normalized_channel, app_build_id, branch)) %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, total_crashes/usage_hours*1000, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    geom_errorbar(position=position_dodge(w=1), width=0.2, mapping=aes(ymin=ymin/usage_hours*1000, ymax=ymax/usage_hours*1000)) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    coord_cartesian(ylim=c(0, 0.03)*1000) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash rate", title="Crashes per 1000 usage-hours: GPU process")
```

```{r shutdown_crashes}
crashes_per_build %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, shutdown_crashes, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash count", title="Shutdown crashes")
```

```{r oom_crashes}
crashes_per_build %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, oom_crashes, fill=branch, alpha=usage_hours)) +
    facet_grid(~normalized_channel, space="free_x", scales="free_x", drop=TRUE) +
    geom_col(position=position_dodge()) +
    scale_alpha_continuous(trans="log10", range=c(0.25, 1)) +
    theme(axis.text.x=element_text(angle=45, hjust=1)) +
    labs(x="Build ID", y="Crash count", title="OOM crashes")
```


# Engagement

```{r intensity}
intensity_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, y, ymin=ymin, ymax=ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(x="Build ID", y="Median", title="Median session intensity (percent)")
```

Error bars reflect bootstrapped 95% confidence intervals for the median.

```{r uri_active_hour}
uri_summary %>%
  inner_join(recent_builds) %>%
  ggplot(aes(app_build_id, user_median, ymin=10**log_ymin, ymax=10**log_ymax, fill=branch)) +
    facet_grid(~normalized_channel, scales="free_x", space="free_x") +
    geom_col(position=position_dodge()) +
    geom_errorbar(width=0.2, position=position_dodge(width=1)) +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    labs(x="Build ID", y="Median", title="URI count per active hour")
```

Error bars reflect 95% confidence intervals for the geometric mean
of the distribution of per-user means, treating the per-user means
as log-normally distributed.

# Bug burndown detail

P1 = Blocking beta

P2 = Blocking release (being worked on or looking for owners)

P3 = Wanted for release, but not blocking

```{r burndown_p1}
burndown %>%
  filter(Priority == "P1") %>%
  ggplot(aes(Day, Count)) +
    geom_line() +
    labs(x="Date", title="P1 bugs") +
    scale_x_date(date_breaks="1 month") +
    expand_limits(y=0)
```
[Bugzilla: P1 blockers][p1]

```{r burndown_p2}
burndown %>%
  filter(Priority == "P2") %>%
  ggplot(aes(Day, Count)) +
    geom_line() +
    labs(x="Date", title="P2 bugs") +
    scale_x_date(date_breaks="1 month") +
    expand_limits(y=0)
```

[Bugzilla: P2 blockers][p2]

```{r burndown_p3}
burndown %>%
  filter(Priority == "P3") %>%
  ggplot(aes(Day, Count)) +
    geom_line() +
    labs(x="Date", title="P3 bugs") +
    scale_x_date(date_breaks="1 month") +
    expand_limits(y=0)
```

[Bugzilla: P3 bugs][p3]


# Enrollment

```{r enrollment, fig.height=4}
ggplot(enrollment_summary, aes(as.Date(submission_date_s3, "%Y%m%d"), n, color=branch)) +
  facet_grid(normalized_channel~slug, scales="free_y") +
  geom_point() +
  labs(x="Date", title="Enrollment events")
```

```{r unenrollment}
unenrollment_summary %>%
  filter(!is.na(branch)) %>%
  ggplot(aes(as.Date(submission_date_s3, "%Y%m%d"), n, fill=reason)) +
    facet_grid(normalized_channel~slug+branch, scales="free_y") +
    geom_col() +
    theme(legend.position="bottom") +
    labs(x="Date", title="Unenrollment events")
```

Counts of users submitting pings considered for performance and crash metrics:

```{r users_by_build_beta}
tryCatch({
  g = users_by_build %>%
    filter(normalized_channel == "beta") %>%
    ggplot(aes(app_build_id, n, fill=factor(experiment))) +
      facet_grid(~branch) +
      geom_col() +
      theme(axis.text.x=element_text(angle=30, hjust=1)) +
      labs(title="Users per build: beta", x="Build ID")
  print(g)
}, error=function(error) cat("No beta users!")
)
```

```{r users_by_build_nightly}
users_by_build %>%
  # inner_join(recent_builds) %>%
  filter(normalized_channel == "nightly") %>%
  ggplot(aes(app_build_id, n, fill=factor(experiment))) +
    facet_grid(~branch) +
    geom_col() +
    theme(axis.text.x=element_text(angle=30, hjust=1)) +
    scale_x_discrete(labels=skip_n(10)) +
    labs(title="Users per build: nightly", x="Build ID") +
    geom_hline(yintercept=125)
```

# Colophon

Please direct questions to tdsmith or the Product Data Science team.

This report follows users enrolled in the experiments
`prefflip-webrender-v1-2-1492568` and
`prefflip-webrender-v1-3-1492568`.

Data are collected from Spark with [this Databricks notebook](https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/50618).

Notebook runs [are kicked off](https://dbc-caf9527b-e073.cloud.databricks.com/#job/715)
at 11am and 11pm UTC and rendered on
[hala](https://mana.mozilla.org/wiki/pages/viewpage.action?pageId=81691528)
at noon and midnight.
The RMarkdown script that renders this page lives
[in Github](https://github.com/tdsmith/webrender-dashboard/).
The "last updated" timestamp reflects the time the ETL task terminated.

Database: `r params$dbname`

[p1]: https://bugzilla.mozilla.org/buglist.cgi?o1=substring&v1=1386669&priority=P1&f1=blocked&resolution=---&query_format=advanced
[p2]: https://bugzilla.mozilla.org/buglist.cgi?o1=substring&v1=1386669&priority=P2&f1=blocked&resolution=---&query_format=advanced
[p3]: https://bugzilla.mozilla.org/buglist.cgi?o1=substring&v1=1386669&priority=P3&f1=blocked&resolution=---&query_format=advanced
